{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7854413,"sourceType":"datasetVersion","datasetId":4606651},{"sourceId":7874753,"sourceType":"datasetVersion","datasetId":4608143},{"sourceId":15981,"sourceType":"modelInstanceVersion","modelInstanceId":13316}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deep-sort-realtime","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:28:48.411302Z","iopub.execute_input":"2024-03-19T05:28:48.411637Z","iopub.status.idle":"2024-03-19T05:29:01.726944Z","shell.execute_reply.started":"2024-03-19T05:28:48.411601Z","shell.execute_reply":"2024-03-19T05:29:01.725799Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting deep-sort-realtime\n  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (1.11.4)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (4.9.0.80)\nDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: deep-sort-realtime\nSuccessfully installed deep-sort-realtime-1.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:29:01.728893Z","iopub.execute_input":"2024-03-19T05:29:01.729213Z","iopub.status.idle":"2024-03-19T05:29:13.967756Z","shell.execute_reply.started":"2024-03-19T05:29:01.729186Z","shell.execute_reply":"2024-03-19T05:29:13.966448Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\n\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch import flatten\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision.transforms import ToTensor\nfrom torchsummary import summary\nimport cv2\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-19T05:29:19.282682Z","iopub.execute_input":"2024-03-19T05:29:19.283077Z","iopub.status.idle":"2024-03-19T05:29:26.989117Z","shell.execute_reply.started":"2024-03-19T05:29:19.283044Z","shell.execute_reply":"2024-03-19T05:29:26.988109Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Faster RCNN","metadata":{}},{"cell_type":"code","source":"from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\nfrom PIL import Image\n\nfasterrcnn=fasterrcnn_resnet50_fpn_v2(pretrained=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:29:34.620680Z","iopub.execute_input":"2024-03-19T05:29:34.621251Z","iopub.status.idle":"2024-03-19T05:29:36.975462Z","shell.execute_reply.started":"2024-03-19T05:29:34.621219Z","shell.execute_reply":"2024-03-19T05:29:36.974580Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n100%|██████████| 167M/167M [00:01<00:00, 156MB/s]  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference On Image","metadata":{}},{"cell_type":"code","source":"fasterrcnn.eval()\ncar_index = 3 \nfilename = '/kaggle/input/car-dataset/img.jpg'\nimg = Image.open(filename) \ntransform = transforms.ToTensor()\nimg_tensor = transform(img).to(device)\nwith torch.no_grad():\n  pred = fasterrcnn([img_tensor])\npred[0].keys()\nbounding_boxes,labels,confidences = pred[0][\"boxes\"],pred[0][\"labels\"],pred[0][\"scores\"]\nlabels,confidences","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.904506Z","iopub.status.idle":"2024-03-19T05:27:30.904969Z","shell.execute_reply.started":"2024-03-19T05:27:30.904721Z","shell.execute_reply":"2024-03-19T05:27:30.904740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = torch.argwhere(confidences>0.9)\nindices=indices.cpu().numpy().flatten()\nindices","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.907003Z","iopub.status.idle":"2024-03-19T05:27:30.907465Z","shell.execute_reply.started":"2024-03-19T05:27:30.907219Z","shell.execute_reply":"2024-03-19T05:27:30.907238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\n\nbounding_boxes1,labels1,confidences1 = bounding_boxes.cpu().numpy(), labels.cpu().numpy(), confidences.cpu().numpy()\n\nfig, ax = plt.subplots(1)\n\n# Plot the image\nax.imshow(img)\n\n# Iterate over bounding boxes and plot them with labels\nfor i in indices:\n    # Get coordinates\n    if(labels1[i].item()==car_index):\n        x, y, w, h = bounding_boxes1[i]\n\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x, y), w - x, h - y, linewidth=1, edgecolor='r', facecolor='none')\n\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n\n        # Add label and confidence score\n        ax.text(x, y, f'{labels1[i].item()} - {confidences1[i].item():.2f}', fontsize=8, color='r')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.908473Z","iopub.status.idle":"2024-03-19T05:27:30.908978Z","shell.execute_reply.started":"2024-03-19T05:27:30.908702Z","shell.execute_reply":"2024-03-19T05:27:30.908723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bounding Box Prediction On Video","metadata":{}},{"cell_type":"code","source":"video = cv2.VideoCapture('/kaggle/input/traffic-junction/Images/Brigade Road/video_20240211_133745.mp4')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.911150Z","iopub.status.idle":"2024-03-19T05:27:30.911903Z","shell.execute_reply.started":"2024-03-19T05:27:30.911636Z","shell.execute_reply":"2024-03-19T05:27:30.911656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inferVideo(model,video, car_index):\n    model.eval()\n    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    out = cv2.VideoWriter('/kaggle/working/brigadeRoad.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 15, (width, height))\n\n    \n    while video.isOpened():\n        # Read the next frame\n        ret, frame = video.read()\n        # Check EOF\n        if not ret:\n            break        \n        transform = transforms.ToTensor()\n        img = transform(frame).to(device)\n        with torch.no_grad():\n          pred = model([img])\n\n        bounding_box,labels,confidence = pred[0][\"boxes\"],pred[0][\"labels\"],pred[0][\"scores\"]\n        indices = torch.argwhere(confidence>0.9)\n        indices=indices.flatten()\n        font = cv2.FONT_HERSHEY_COMPLEX\n        bounding_box1=bounding_box.cpu().numpy()\n        labels1=labels.cpu().numpy()\n\n        if(len(indices)!=0):\n            for i in indices:\n                if(labels1[i] == car_index):\n                    x1,y1,x2,y2 = bounding_box1[i].astype('int')\n                    cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),2)\n                    cv2.putText(frame,\"car\",(x1,y1),font,0.5,(255,0,0),cv2.LINE_AA)\n\n        out.write(frame)\n\n    # Release the video capture object and close the window\n    out.release()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.912954Z","iopub.status.idle":"2024-03-19T05:27:30.913402Z","shell.execute_reply.started":"2024-03-19T05:27:30.913162Z","shell.execute_reply":"2024-03-19T05:27:30.913180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inferVideo(fasterrcnn,video,3)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:27:30.914633Z","iopub.status.idle":"2024-03-19T05:27:30.915082Z","shell.execute_reply.started":"2024-03-19T05:27:30.914856Z","shell.execute_reply":"2024-03-19T05:27:30.914875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Faster RCNN + DEEPSORT","metadata":{}},{"cell_type":"code","source":"from deep_sort_realtime.deepsort_tracker import DeepSort \n\nvideo = cv2.VideoCapture('/kaggle/input/traffic-junction/Images/Images/Vidhana Soudha/video_20240211_142947.mp4')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:47:59.386909Z","iopub.execute_input":"2024-03-19T05:47:59.387293Z","iopub.status.idle":"2024-03-19T05:47:59.445216Z","shell.execute_reply.started":"2024-03-19T05:47:59.387261Z","shell.execute_reply":"2024-03-19T05:47:59.444255Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"object_tracker = DeepSort(max_iou_distance=0.2,max_age=20,nms_max_overlap = 0.05,gating_only_position=True,n_init=2,max_cosine_distance=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:48:01.079707Z","iopub.execute_input":"2024-03-19T05:48:01.080448Z","iopub.status.idle":"2024-03-19T05:48:01.192233Z","shell.execute_reply.started":"2024-03-19T05:48:01.080412Z","shell.execute_reply":"2024-03-19T05:48:01.191416Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def TrackCar(model,video, car_index,object_tracker,out_path):\n    model.eval()\n    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), 15, (width, height))\n    setIDs=set()\n    \n    while video.isOpened():\n        # Read the next frame\n        ret, frame = video.read()\n        if not ret:\n            break\n            \n        transform = transforms.ToTensor()\n        img = transform(frame).to(device)\n        with torch.no_grad():\n          pred = model([img])\n        \n\n        #Creating Detection data for cars to pass into SORT tracks directly \n        \n        bounding_box,labels,confidence = pred[0][\"boxes\"],pred[0][\"labels\"],pred[0][\"scores\"]\n        indices = torch.argwhere(confidence>0.9)\n        indices=indices.flatten()\n        font = cv2.FONT_HERSHEY_COMPLEX\n        bounding_box1=bounding_box.cpu().numpy()\n        labels1=labels.cpu().numpy()\n        confidences=confidence.cpu().numpy()\n        \n        detections = [] \n        \n        if(len(indices)!=0):\n            for i in indices:\n                if(labels1[i] == car_index):\n                    x1,y1,x2,y2 = bounding_box1[i].astype('int')\n                    x,y,w,h = [x1, y1,int(abs(x2-x1)),int(abs(y2-y1))]\n                    detections.append(([x,y,w,h],confidences[i],'car'))\n    \n            tracks = object_tracker.update_tracks(detections, frame=frame)\n            \n            for track in tracks:\n                if not track.is_confirmed():\n                    continue\n                track_id = track.track_id\n                setIDs.add(track_id)\n                ltrb = track.to_ltrb()\n                bbox = ltrb\n                cv2.rectangle(frame,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,0,255),2)\n                cv2.putText(frame, \"ID: \" + str(track_id), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n            #Count \n#             count = object_tracker.tracker._next_id-1 \n            count=len(setIDs)\n            cv2.putText(frame, f'Count: {int(count)}', (20,100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n\n            out.write(frame)\n        \n    out.release()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:48:02.712802Z","iopub.execute_input":"2024-03-19T05:48:02.713569Z","iopub.status.idle":"2024-03-19T05:48:02.728770Z","shell.execute_reply.started":"2024-03-19T05:48:02.713536Z","shell.execute_reply":"2024-03-19T05:48:02.727754Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"TrackCar(fasterrcnn,video,3,object_tracker,'/kaggle/working/VidhanaSoundha2.mp4')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:48:05.316776Z","iopub.execute_input":"2024-03-19T05:48:05.317436Z","iopub.status.idle":"2024-03-19T05:48:41.538518Z","shell.execute_reply.started":"2024-03-19T05:48:05.317399Z","shell.execute_reply":"2024-03-19T05:48:41.537477Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# FasterRCNN + SORT","metadata":{}},{"cell_type":"code","source":"!pip install gitpython","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:50:04.660052Z","iopub.execute_input":"2024-03-19T05:50:04.660994Z","iopub.status.idle":"2024-03-19T05:50:16.648562Z","shell.execute_reply.started":"2024-03-19T05:50:04.660959Z","shell.execute_reply":"2024-03-19T05:50:16.647376Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython in /opt/conda/lib/python3.10/site-packages (3.1.41)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython) (4.0.11)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nimport git\nimport sys\n\n#Uncomment like below if running it for 2nd time or more\n\n# shutil.rmtree('/kaggle/working/sample1')\n\ngit.Repo.clone_from('https://github.com/KalyanRam1234/sort.git', '/kaggle/working/sample1')\nsys.path.insert(0,'/kaggle/working/sample1/')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:50:27.564101Z","iopub.execute_input":"2024-03-19T05:50:27.564493Z","iopub.status.idle":"2024-03-19T05:50:28.509120Z","shell.execute_reply.started":"2024-03-19T05:50:27.564463Z","shell.execute_reply":"2024-03-19T05:50:28.508207Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"%pip install filterpy==1.4.5\n# %pip install scikit-image==0.17.2\n%pip install lap==0.4.0","metadata":{"execution":{"iopub.status.busy":"2024-03-19T05:50:31.391992Z","iopub.execute_input":"2024-03-19T05:50:31.392723Z","iopub.status.idle":"2024-03-19T05:51:09.161620Z","shell.execute_reply.started":"2024-03-19T05:50:31.392694Z","shell.execute_reply":"2024-03-19T05:51:09.160322Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Collecting filterpy==1.4.5\n  Downloading filterpy-1.4.5.zip (177 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from filterpy==1.4.5) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from filterpy==1.4.5) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from filterpy==1.4.5) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->filterpy==1.4.5) (1.16.0)\nBuilding wheels for collected packages: filterpy\n  Building wheel for filterpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=b81046cd790c207cdb418d358674b4ddfd41cb52d7846143622a99e51f8ffe59\n  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\nSuccessfully built filterpy\nInstalling collected packages: filterpy\nSuccessfully installed filterpy-1.4.5\nNote: you may need to restart the kernel to use updated packages.\nCollecting lap==0.4.0\n  Downloading lap-0.4.0.tar.gz (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: lap\n  Building wheel for lap (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp310-cp310-linux_x86_64.whl size=1483137 sha256=3bb02d22c1a862e62f79b5461e4f18cc3dcd442c005249ec22707dde5fbd94db\n  Stored in directory: /root/.cache/pip/wheels/00/42/2e/9dfe19270eea279d79e84767ff0d7b8082c3bf776cad00e83d\nSuccessfully built lap\nInstalling collected packages: lap\nSuccessfully installed lap-0.4.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sort import *","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:07:26.076698Z","iopub.execute_input":"2024-03-19T06:07:26.077636Z","iopub.status.idle":"2024-03-19T06:07:26.081796Z","shell.execute_reply.started":"2024-03-19T06:07:26.077600Z","shell.execute_reply":"2024-03-19T06:07:26.080826Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"video = cv2.VideoCapture('/kaggle/input/traffic-junction/Images/Images/Vidhana Soudha/video_20240211_142947.mp4')\nobject_tracker = Sort(max_age=600, min_hits=2)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:29:44.853615Z","iopub.execute_input":"2024-03-19T06:29:44.854568Z","iopub.status.idle":"2024-03-19T06:29:44.904729Z","shell.execute_reply.started":"2024-03-19T06:29:44.854533Z","shell.execute_reply":"2024-03-19T06:29:44.903924Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def TrackCarSort(model,video, car_index,object_tracker,out_path):\n    model.eval()\n    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), 15, (width, height))\n    \n    setIDs=set()\n    while video.isOpened():\n        # Read the next frame\n        ret, frame = video.read()\n        if not ret:\n            break\n            \n        transform = transforms.ToTensor()\n        img = transform(frame).to(device)\n        with torch.no_grad():\n          pred = model([img])\n        \n\n        #Creating Detection data for cars to pass into SORT tracks directly \n        \n        bounding_box,labels,confidence = pred[0][\"boxes\"],pred[0][\"labels\"],pred[0][\"scores\"]\n        indices = torch.argwhere(confidence>0.9)\n        indices=indices.flatten()\n        font = cv2.FONT_HERSHEY_COMPLEX\n        bounding_box1=bounding_box.cpu().numpy()\n        labels1=labels.cpu().numpy()\n        confidences=confidence.cpu().numpy()\n        \n        detections = [] \n        \n        if(len(indices)!=0):\n            for i in indices:\n                if(labels1[i] == car_index):\n                    x1,y1,x2,y2 = bounding_box1[i].astype('int')\n                    x,y,w,h = [int(x1), int(y1),int(abs(x2-x1)),int(abs(y2-y1))]\n                    detections.append([int(x1),int(y1),int(x2),int(y2)])\n            \n            if(len(detections)==0): continue \n\n            detections=np.array(detections)\n            tracks = object_tracker.update(detections)\n\n            for id ,track in enumerate(tracks):\n                bbox=track\n                track_id=track[4]\n                setIDs.add(track_id)\n                cv2.rectangle(frame,(int(bbox[0]),int(bbox[1])),(int(bbox[2]),int(bbox[3])),(0,0,255),2)\n                cv2.putText(frame, \"ID: \" + str(track_id), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n            count=len(setIDs)\n            cv2.putText(frame, f'Count: {int(count)}', (20,100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n\n            out.write(frame)\n#             break\n        \n    out.release()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:29:46.443329Z","iopub.execute_input":"2024-03-19T06:29:46.444195Z","iopub.status.idle":"2024-03-19T06:29:46.459982Z","shell.execute_reply.started":"2024-03-19T06:29:46.444162Z","shell.execute_reply":"2024-03-19T06:29:46.459109Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"TrackCarSort(fasterrcnn,video,3,object_tracker,'/kaggle/working/VidhanaSort2.mp4')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:30:10.083283Z","iopub.execute_input":"2024-03-19T06:30:10.084137Z","iopub.status.idle":"2024-03-19T06:30:48.652961Z","shell.execute_reply.started":"2024-03-19T06:30:10.084105Z","shell.execute_reply":"2024-03-19T06:30:48.651429Z"},"trusted":true},"execution_count":82,"outputs":[]}]}